# LRU 缓存工作流程可视化

## cacheLookup 函数流程图

```
开始: cacheLookup(key, dataRetriever)
         |
         v
  在哈希表中查找 key
         |
         +------------------+
         |                  |
      找到了？          找不到？
         |                  |
    【缓存命中】        【缓存未命中】
         |                  |
         |                  v
         |            缓存是否已满？
         |                  |
         |            +-----+-----+
         |            |           |
         |          已满       未满
         |            |           |
         |            v           |
         |       驱逐 LRU        |
         |       (队列头)        |
         |            |           |
         |            v           v
         |         调用 dataRetriever
         |         获取数据
         |            |
         |            v
         |         加入缓存
         |         (哈希表 + 队列尾)
         |            |
         +------------+
                |
                v
         更新访问顺序
         (移到队列尾)
                |
                v
            返回数据
                |
                v
              结束
```

## 数据结构关系图

```
LRUCache (容量: 3)
├─ 哈希表 (HashMap)
│  ├─ [key: 1] → CacheEntry { key:1, value:"A", node: → }
│  ├─ [key: 2] → CacheEntry { key:2, value:"B", node: → }
│  └─ [key: 3] → CacheEntry { key:3, value:"C", node: → }
│
└─ 队列 (Queue - 双向链表)
   ┌────────────────────────────────────────┐
   │  [1] ←→ [2] ←→ [3]                    │
   │   ↑           ↑                        │
   │  front       back                      │
   │  (LRU)      (MRU)                      │
   └────────────────────────────────────────┘
   
说明:
- front (队列头) = 最久未使用 (Least Recently Used)
- back (队列尾) = 最近使用 (Most Recently Used)
- 每个 CacheEntry 的 node 指针指向队列中对应的节点
```

## 操作示例演示

### 场景 1: 缓存命中

```
初始状态 (容量: 3):
哈希表: {1:"A", 2:"B", 3:"C"}
队列:   [1] ←→ [2] ←→ [3]
        LRU         MRU

操作: cacheLookup(2, dataRetriever)
        ↓
1. 在哈希表中找到 key=2 ✓
2. 不调用 dataRetriever
3. 将 2 从队列中移除
4. 将 2 添加到队列尾部

结果状态:
哈希表: {1:"A", 2:"B", 3:"C"}  (不变)
队列:   [1] ←→ [3] ←→ [2]
        LRU         MRU
        
返回: "B" (快速，无需访问慢速数据源！)
```

### 场景 2: 缓存未命中 + 驱逐

```
初始状态 (容量: 3, 已满):
哈希表: {1:"A", 2:"B", 3:"C"}
队列:   [1] ←→ [2] ←→ [3]
        LRU         MRU

操作: cacheLookup(4, dataRetriever)
        ↓
1. 在哈希表中找不到 key=4 ✗
2. 缓存已满，需要驱逐
3. 驱逐队列头部 (key=1)
   - 从队列中移除 1
   - 从哈希表中删除 1
4. 调用 dataRetriever(4) → 获得 "D"
5. 将 4 加入缓存
   - 添加到哈希表
   - 添加到队列尾部

结果状态:
哈希表: {2:"B", 3:"C", 4:"D"}
队列:   [2] ←→ [3] ←→ [4]
        LRU         MRU
        
返回: "D" (需要访问慢速数据源)
```

## 访问模式分析

### 示例: Web 浏览器访问网页

```
页面访问序列: [A, B, C, A, D, A]
缓存容量: 2

步骤 1: 访问 A
  缓存: [A]
  结果: 未命中，加载 A
  
步骤 2: 访问 B  
  缓存: [A] ←→ [B]
  结果: 未命中，加载 B
  
步骤 3: 访问 C
  缓存已满，驱逐 A
  缓存: [B] ←→ [C]
  结果: 未命中，加载 C
  
步骤 4: 访问 A
  缓存已满，驱逐 B
  缓存: [C] ←→ [A]
  结果: 未命中，加载 A
  
步骤 5: 访问 D
  缓存已满，驱逐 C
  缓存: [A] ←→ [D]
  结果: 未命中，加载 D
  
步骤 6: 访问 A
  缓存: [D] ←→ [A]
  结果: ✓ 命中！直接从缓存返回

统计:
- 总访问: 6 次
- 缓存命中: 1 次 (16.7%)
- 缓存未命中: 5 次
```

## 性能对比

### 有缓存 vs 无缓存

```
场景: 100 次访问，80% 的访问集中在 20% 的数据（典型的 80-20 规则）

无缓存:
┌──────────────────────────────────────────┐
│ 每次访问都需要慢速数据源查询              │
│ 总查询: 100 次                           │
│ 平均响应时间: 100ms                      │
│ 总时间: 10,000ms (10秒)                 │
└──────────────────────────────────────────┘

有 LRU 缓存 (容量适当):
┌──────────────────────────────────────────┐
│ 缓存命中: 80 次 (1ms 响应)              │
│ 缓存未命中: 20 次 (100ms 响应)          │
│ 总时间: 80×1 + 20×100 = 2,080ms (2秒)   │
│ 性能提升: 4.8x 倍！                     │
└──────────────────────────────────────────┘
```

## LRU vs 其他策略

```
场景: 访问序列 [1, 2, 3, 4, 1, 2, 5, 1, 2, 3]
缓存容量: 3

策略 1: LRU (Least Recently Used)
  [1,2,3] → [2,3,4] → [3,4,1] → [4,1,2] → [1,2,5] → [2,5,1] → [5,1,2] → [1,2,3]
  命中次数: 4 次

策略 2: FIFO (First In First Out)
  [1,2,3] → [2,3,4] → [3,4,1] → [4,1,2] → [1,2,5] → [2,5,1] → [5,1,2] → [1,2,3]
  命中次数: 2 次
  
策略 3: LFU (Least Frequently Used) - 统计访问次数
  维护访问计数，驱逐访问次数最少的
  命中次数: 5 次
  
结论: 不同策略适合不同的访问模式！
```

## 咖啡店类比（书中例子）

```
咖啡店柜台布局:

远端                                            收银台
┌────────────────┐                          ┌──────┐
│  咖啡站         │                          │ LRU  │
│  (慢速存储)    │  ← 很远的距离 →         │ 缓存 │
│                 │                          │      │
│ ☕ House Brew   │                          │ ☕   │
│ ☕ Decaf        │                          │      │
│ ☕ Espresso     │                          │      │
│ ☕ Latte        │                          │      │
│ ☕ Mocha        │                          │      │
│ ...             │                          │      │
└────────────────┘                          └──────┘

场景 1: 缓存命中
  顾客: "一杯 House Brew"
  咖啡师: 收银台旁就有！✓ (3秒)
  
场景 2: 缓存未命中
  顾客: "一杯 Mocha"
  咖啡师: 得走到远端取... (30秒)
  
场景 3: LRU 策略
  - 收银台只能放 2 个咖啡壶
  - 当前: [House Brew, Decaf]
  - 顾客连续点了 3 杯 Espresso
  - 决定替换最久没被点的 Decaf
  - 更新为: [House Brew, Espresso]
```

## 实现技巧

### 为什么需要哈希表 + 队列？

```
只用哈希表:
  ✓ O(1) 查找
  ✗ 无法知道哪个是 LRU
  ✗ 需要 O(n) 扫描找最久未使用的

只用队列:
  ✓ O(1) 找到 LRU (队列头)
  ✗ O(n) 查找特定 key
  ✗ O(n) 更新访问时间

哈希表 + 队列:
  ✓ O(1) 查找 (哈希表)
  ✓ O(1) 找到 LRU (队列头)
  ✓ O(1) 更新访问时间 (通过 node 指针)
  完美！
```

## 关键设计决策

1. **双向链表**: 允许 O(1) 删除中间节点
2. **node 指针**: CacheEntry 保存指向队列节点的指针，快速定位
3. **模板**: 支持任意键值类型
4. **std::function**: 灵活的数据检索函数
5. **std::optional**: 清晰表示"未找到"的情况

---

这个可视化展示了 LRU 缓存的核心思想和实现细节，希望能帮助理解！
